{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import load\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ready-made DataFrame\n"
     ]
    }
   ],
   "source": [
    "wesad = load.WESAD()\n",
    "df = wesad.separate_and_feature_extract(sample_n=420000) #700 * 60 * 10 (10mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 59, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[:, 0, 0]  # 取得 'label'\n",
    "X = df[:, :, 2:]  # 移除 'label','subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dtype: float32\n",
      "y dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "\n",
    "y = np.array(y, dtype=np.int32)\n",
    "\n",
    "print(\"X dtype:\", X.dtype)  # 應該是 float32\n",
    "print(\"y dtype:\", y.dtype)  # 應該是 int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割訓練測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=5, activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=5, activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "    model.add(layers.LSTM(64))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 18)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2]) #(59,18)\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(input_shape)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorflow\\.venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.4514 - loss: 2.0589 - val_accuracy: 0.3333 - val_loss: 1.8420\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5347 - loss: 1.3115 - val_accuracy: 0.8333 - val_loss: 0.5622\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5069 - loss: 0.7084 - val_accuracy: 0.6667 - val_loss: 0.5378\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6944 - loss: 0.6224 - val_accuracy: 0.8333 - val_loss: 0.6497\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5833 - loss: 0.6486 - val_accuracy: 0.5000 - val_loss: 0.8016\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6181 - loss: 0.6727 - val_accuracy: 0.6667 - val_loss: 0.5567\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6736 - loss: 0.6096 - val_accuracy: 0.8333 - val_loss: 0.4778\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5278 - loss: 0.6894 - val_accuracy: 0.6667 - val_loss: 0.4733\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7014 - loss: 0.5999 - val_accuracy: 0.8333 - val_loss: 0.5922\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6736 - loss: 0.5890 - val_accuracy: 0.6667 - val_loss: 0.6339\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5556 - loss: 0.6222 - val_accuracy: 0.6667 - val_loss: 0.5516\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7222 - loss: 0.5379 - val_accuracy: 0.5000 - val_loss: 0.5565\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8264 - loss: 0.5242 - val_accuracy: 0.5000 - val_loss: 0.6109\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.5086 - val_accuracy: 0.5000 - val_loss: 0.6507\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.5263 - val_accuracy: 0.5000 - val_loss: 0.6494\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7986 - loss: 0.4715 - val_accuracy: 0.5000 - val_loss: 0.7355\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6944 - loss: 0.4919 - val_accuracy: 0.5000 - val_loss: 0.8168\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7708 - loss: 0.4811 - val_accuracy: 0.6667 - val_loss: 0.8657\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7778 - loss: 0.4981 - val_accuracy: 0.5000 - val_loss: 0.6961\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6944 - loss: 0.4271 - val_accuracy: 0.5000 - val_loss: 0.8796\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8264 - loss: 0.4601 - val_accuracy: 0.6667 - val_loss: 1.1371\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7292 - loss: 0.5551 - val_accuracy: 0.5000 - val_loss: 0.7467\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6944 - loss: 0.4496 - val_accuracy: 0.5000 - val_loss: 0.7416\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6319 - loss: 0.4584 - val_accuracy: 0.6667 - val_loss: 1.1428\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7292 - loss: 0.4794 - val_accuracy: 0.6667 - val_loss: 1.1330\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8264 - loss: 0.3672 - val_accuracy: 0.5000 - val_loss: 1.0362\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8194 - loss: 0.3378 - val_accuracy: 0.5000 - val_loss: 1.0828\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8194 - loss: 0.3186 - val_accuracy: 0.6667 - val_loss: 1.3049\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8958 - loss: 0.3681 - val_accuracy: 0.6667 - val_loss: 1.3181\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9236 - loss: 0.3494 - val_accuracy: 0.5000 - val_loss: 1.0594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25b9e7cff10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.50      0.40         2\n",
      "           2       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.50      0.50      0.49         6\n",
      "weighted avg       0.56      0.50      0.51         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# 將機率轉換為 0 或 1（閾值設為 0.5）\n",
    "y_pred_classes = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "y_pred_single = np.argmax(y_pred_classes, axis=1)\n",
    "\n",
    "# 輸出分類報告\n",
    "report = classification_report(y_test, y_pred_single, target_names=['1', '2'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorflow\\.venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 308ms/step - accuracy: 0.5694 - loss: 0.6894 - val_accuracy: 0.3333 - val_loss: 0.8357\n",
      "Epoch 2/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5069 - loss: 0.7397 - val_accuracy: 0.3333 - val_loss: 0.7811\n",
      "Epoch 3/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5278 - loss: 0.7014 - val_accuracy: 0.3333 - val_loss: 0.7324\n",
      "Epoch 4/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5486 - loss: 0.6759 - val_accuracy: 0.8333 - val_loss: 0.6576\n",
      "Epoch 5/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5208 - loss: 0.6812 - val_accuracy: 0.6667 - val_loss: 0.6334\n",
      "Epoch 6/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6806 - loss: 0.6633 - val_accuracy: 0.6667 - val_loss: 0.6693\n",
      "Epoch 7/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5764 - loss: 0.6504 - val_accuracy: 0.6667 - val_loss: 0.6734\n",
      "Epoch 8/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5972 - loss: 0.6342 - val_accuracy: 0.6667 - val_loss: 0.5761\n",
      "Epoch 9/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7431 - loss: 0.6217 - val_accuracy: 0.8333 - val_loss: 0.5523\n",
      "Epoch 10/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6806 - loss: 0.6215 - val_accuracy: 0.6667 - val_loss: 0.6421\n",
      "Epoch 11/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6250 - loss: 0.6143 - val_accuracy: 0.6667 - val_loss: 0.5852\n",
      "Epoch 12/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7986 - loss: 0.5370 - val_accuracy: 0.8333 - val_loss: 0.5123\n",
      "Epoch 13/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6944 - loss: 0.6505 - val_accuracy: 0.8333 - val_loss: 0.4945\n",
      "Epoch 14/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6736 - loss: 0.6083 - val_accuracy: 0.8333 - val_loss: 0.6500\n",
      "Epoch 15/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8194 - loss: 0.5309 - val_accuracy: 0.6667 - val_loss: 0.7432\n",
      "Epoch 16/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6736 - loss: 0.6150 - val_accuracy: 0.6667 - val_loss: 0.5745\n",
      "Epoch 17/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8681 - loss: 0.5261 - val_accuracy: 0.8333 - val_loss: 0.4953\n",
      "Epoch 18/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6250 - loss: 0.6584 - val_accuracy: 0.8333 - val_loss: 0.5145\n",
      "Epoch 19/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7500 - loss: 0.5606 - val_accuracy: 0.6667 - val_loss: 0.6402\n",
      "Epoch 20/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.5575 - val_accuracy: 0.6667 - val_loss: 0.6975\n",
      "Epoch 21/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7639 - loss: 0.5325 - val_accuracy: 0.5000 - val_loss: 0.6211\n",
      "Epoch 22/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7778 - loss: 0.4992 - val_accuracy: 0.8333 - val_loss: 0.4811\n",
      "Epoch 23/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6528 - loss: 0.6243 - val_accuracy: 0.8333 - val_loss: 0.4826\n",
      "Epoch 24/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6528 - loss: 0.5924 - val_accuracy: 0.6667 - val_loss: 0.6407\n",
      "Epoch 25/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7778 - loss: 0.5064 - val_accuracy: 0.6667 - val_loss: 0.7073\n",
      "Epoch 26/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7292 - loss: 0.5836 - val_accuracy: 0.6667 - val_loss: 0.6821\n",
      "Epoch 27/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8194 - loss: 0.4445 - val_accuracy: 0.6667 - val_loss: 0.5916\n",
      "Epoch 28/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7083 - loss: 0.5203 - val_accuracy: 0.6667 - val_loss: 0.5012\n",
      "Epoch 29/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6597 - loss: 0.6102 - val_accuracy: 0.6667 - val_loss: 0.5434\n",
      "Epoch 30/30\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.4822 - val_accuracy: 0.6667 - val_loss: 0.6729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25b9e7cf400>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model = build_cnn_lstm_model(input_shape, num_classes)\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50         2\n",
      "           2       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.62      0.62      0.62         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# 將機率轉換為 0 或 1（閾值設為 0.5）\n",
    "y_pred_classes = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "y_pred_single = np.argmax(y_pred_classes, axis=1)\n",
    "\n",
    "# 輸出分類報告\n",
    "report = classification_report(y_test, y_pred_single, target_names=['1', '2'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選擇 LSTM 是因為 生理訊號屬於時間序列數據，LSTM 能夠記住過去的資訊，並利用這些資訊影響未來的預測。\n",
    "# 此外，LSTM 透過 記憶單元與門機制，有效解決了傳統 RNN 中的 梯度消失問題，使模型能夠學習並捕捉長時間的依賴關係，從而提升壓力偵測的準確性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
